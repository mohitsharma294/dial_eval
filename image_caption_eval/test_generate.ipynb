{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c615963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a97df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"dailydialog_v3/large_key_m10/checkpoint-38032\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d588da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, model_name, tokenizer, use_key, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.lm = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.lm.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        if(use_key):\n",
    "            #self.bow_head = torch.nn.Linear(hidden_size, tokenizer.vocab_size, bias=False)\n",
    "            self.bow_head = torch.nn.Linear(hidden_size, len(tokenizer), bias=False)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels, key_ids = None):\n",
    "        if(use_key):\n",
    "            lm_out = self.lm(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                           labels=labels, output_hidden_states=True)\n",
    "            hidden = lm_out.decoder_hidden_states[-1]\n",
    "            h = torch.permute(hidden, (1, 0, 2))[0]\n",
    "            fc1 = self.bow_head(h)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            \n",
    "            b_size = key_ids.size(0)\n",
    "            bow_loss = 0\n",
    "            for i in range(b_size):\n",
    "                bow_ids = key_ids[i]\n",
    "                bow_logits = fc1[i]\n",
    "                bow_logits = bow_logits.expand(bow_ids.size(0), -1)\n",
    "                #b_loss = torch.nan_to_num(loss_fct(bow_logits, bow_ids))\n",
    "                b_loss = loss_fct(bow_logits, bow_ids)\n",
    "                bow_loss+=b_loss\n",
    "            bow_loss = bow_loss/b_size\n",
    "            loss = (bow_wt*bow_loss) + lm_out.loss\n",
    "        else:\n",
    "            lm_out = self.lm(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = lm_out.loss\n",
    "        return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70a8e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "MODEL_CKPT = \"t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(best_model_path)\n",
    "raw_model = Model(MODEL_CKPT, tokenizer, True, 1024)\n",
    "m_path = os.path.join(best_model_path, \"pytorch_model.bin\")\n",
    "raw_model.load_state_dict(torch.load(m_path, map_location=torch.device('cpu')))\n",
    "raw_model.eval()\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00934f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 43])\n",
      "tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "ctx = \"Hey man , you wanna buy some weed ?<eou>Some what ?<eou>Weed ! You know ? Pot , Ganja , Mary Jane some chronic !<eou>Oh , umm , no thanks .<eou>I also have blow if you prefer to do a few lines .<eou>\"\n",
    "#output = tokenizer(ctx, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "ctx = \"Hey man , you wanna buy some weed ?<eou>Some what ?<eou>Weed ! You know ? Pot , Ganja , Mary Jane some chronic !<eou>\"\n",
    "#output = tokenizer(ctx, max_length=512, truncation=True, padding = 'max_length', return_tensors=\"pt\")\n",
    "output = tokenizer(ctx, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "dec_inp = torch.tensor([[0]], dtype=output.input_ids.dtype)\n",
    "print(output[\"input_ids\"].shape)\n",
    "print(dec_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75d63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4b959cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Yeah, that's what I was thinking.\"]\n",
      "torch.Size([1, 1, 1024])\n",
      "torch.Size([1, 32102])\n",
      "[[32101, 3, 7, 17945, 63, 15, 9, 207]]\n",
      "['<nok>', '▁', 's', '▁yeah', 'y', 'e', 'a', '▁good']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_ids = output[\"input_ids\"]\n",
    "    attention_mask = output[\"attention_mask\"]\n",
    "    out = raw_model.lm.generate(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                decoder_input_ids=dec_inp,\n",
    "                                num_beams=5, max_new_tokens=41, min_new_tokens=12, \n",
    "                            length_penalty=0.1)\n",
    "    \n",
    "    \n",
    "    utt = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "    print(utt)\n",
    "    \n",
    "    lm_out = raw_model.lm(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                           decoder_input_ids=dec_inp, output_hidden_states=True)\n",
    "    \n",
    "    hidden = lm_out.decoder_hidden_states[-1]\n",
    "    print(hidden.shape)\n",
    "    h = torch.permute(hidden, (1, 0, 2))[0]\n",
    "    fc1 = raw_model.bow_head(h)\n",
    "    print(fc1.shape)\n",
    "    \n",
    "    val, indices = torch.topk(fc1, 8)\n",
    "    \n",
    "    lst_idx = indices.tolist()\n",
    "    print(lst_idx)\n",
    "    lst_tok = tokenizer.convert_ids_to_tokens(lst_idx[0])\n",
    "    print(lst_tok)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4933501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  -1,   -2,    4, -100,  -20],\n",
      "        [   1,    8,    4, -100,   20]])\n",
      "tensor([[ 4, -1, -2],\n",
      "        [20,  8,  4]])\n",
      "tensor([[2, 0, 1],\n",
      "        [4, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[-1,-2,4,-100, -20], [1,8,4,-100, 20]])\n",
    "print(x)\n",
    "val, indices = torch.topk(x, 3)\n",
    "print(val)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b1fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "con",
   "language": "python",
   "name": "con"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
